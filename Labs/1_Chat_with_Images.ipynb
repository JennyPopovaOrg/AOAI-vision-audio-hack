{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with Azure OpenAI vision models\n",
    "\n",
    "**If you're looking for the web application, check the src/ folder.**\n",
    "\n",
    "GPT-4o is the latest model from OpenAI. GPT-4o integrates text and images in a single model, enabling it to handle multiple data types simultaneously. This multimodal approach enhances accuracy and responsiveness in human-computer interactions. GPT-4o matches GPT-4 Turbo in English text and coding tasks while offering superior performance in non-English languages and vision tasks, setting new benchmarks for AI capabilities.\n",
    "\n",
    "Documentation: https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4o-and-gpt-4-turbo\n",
    "\n",
    "In this lab we will try different variants of using GPT-4o model for image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to OpenAI\n",
    "\n",
    "The following code connects to OpenAI using an Azure OpenAI account. See the README for instruction on configuring the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "from IPython.display import Image\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    # Authenticate using an Azure OpenAI API key\n",
    "    # This is generally discouraged, but is provided for developers\n",
    "    # that want to develop locally inside the Docker container.\n",
    "print(\"Using Azure OpenAI with key\")\n",
    "openai_client = openai.AzureOpenAI(\n",
    "        api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-02-15-preview\",\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    )\n",
    "\n",
    "# Set the model name\n",
    "OPENAI_MODEL= os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "print(\"Model name:\", OPENAI_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Drawing a Unicorn\n",
    "\n",
    "In this exercise, you will use GPT-4 to generate step-by-step instructions on how to draw a unicorn using an image of aurochs as an input.  \n",
    "The goal is to leverage the capabilities of the Azure OpenAI service to provide extensive analysis of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send an image by web URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  \"https://upload.wikimedia.org/wikipedia/commons/6/6e/Ur-painting.jpg\" #image URL\n",
    "prompt = \"Is this a unicorn?\" # text prompt to OpenAI model\n",
    "\n",
    "# Send the prompt and image to the model\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": prompt, \"type\": \"text\"},\n",
    "            {\n",
    "                \"image_url\": {\"url\": url},\n",
    "                \"type\": \"image_url\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "response = openai_client.chat.completions.create(model=OPENAI_MODEL, messages=messages, temperature=0.5)\n",
    "\n",
    "# Display the image and the model's response\n",
    "display(Image(url=url, width=200))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send an image by Data URI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to read and encode image file for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to open an image file and return it as a base64 encoded string\n",
    "import base64\n",
    "\n",
    "def open_image_as_base64(filename):\n",
    "    with open(filename, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "    image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "    return f\"data:image/png;base64,{image_base64}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/ur.jpg\" #image file URL\n",
    "prompt = \"how could I make this into a unicorn though??\" # text prompt to OpenAI model\n",
    "\n",
    "# Send the prompt and image to the model\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Display the image and the model's response\n",
    "display(Image(url=url, width=200))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph analysis\n",
    "\n",
    "In this exercise you will investigate GPT-4 ability to understand and and extract informationfrom graphs and charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/20210331_Global_tree_cover_loss_-_World_Resources_Institute.svg/1280px-20210331_Global_tree_cover_loss_-_World_Resources_Institute.svg.png\"\n",
    "prompt = \"What zone are we losing the most trees in?\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": prompt, \"type\": \"text\"},\n",
    "            {\n",
    "                \"image_url\": {\n",
    "                    \"url\": url\n",
    "                },\n",
    "                \"type\": \"image_url\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "response = openai_client.chat.completions.create(model=OPENAI_MODEL, messages=messages, temperature=0.5)\n",
    "\n",
    "display(Image(url=url, width=400))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Insurance claim processing\n",
    "\n",
    "See how GPT-4 can help with business processes that include visual assessment, for example, insurance claim processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/dented_car.jpg\"\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an AI assistant that helps auto insurance companies process claims.\"\n",
    "                \"You accept images of damaged cars that are submitted with claims, and you are able to make judgments \"\n",
    "                \"about the causes of automobile damage, and the validity of claims regarding that damage.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": \"Claim states that this damage is due to hail. Is it valid?\", \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=400))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Appliance help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/dishwasher.png\"\n",
    "prompt = \"How do I set this to wash the dishes quickly?\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=800))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assistance for vision-impaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/menu.png\"\n",
    "prompt = \"is there anything good for vegans on this menu?\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=400))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Describe IT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/azure_arch.png\"\n",
    "prompt = \"Suggest an alt text for this image\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=400))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Table analysis\n",
    "\n",
    "GPT-4o can understand and extract information from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/page_0.png\"\n",
    "prompt = \"What's the cheapest plant?\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=600))\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Recommendation based on image analysis\n",
    "\n",
    "GPT-4o can provide recommendations based on image content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../data/images/fridge.jpg\"\n",
    "prompt = \"Propose me a meal based on the contents of my fridge\"   \n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=400))  \n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Challenge\n",
    "\n",
    "Try your own images and different prompts for Image analysis with Azure OpenAI GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analyse image from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your image path and prompt here \n",
    "\n",
    "url = \"...\" #add yor image path here\n",
    "prompt = \"...\"   # add your prompt here\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=OPENAI_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": prompt, \"type\": \"text\"},\n",
    "                {\"image_url\": {\"url\": open_image_as_base64(url)}, \"type\": \"image_url\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(Image(url=url, width=400))  \n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Analyse image from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your image url and prompt here\n",
    "\n",
    "url =  \"...\" #add your image url here\n",
    "prompt = \"...\"   # add your prompt here\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": prompt, \"type\": \"text\"},\n",
    "            {\n",
    "                \"image_url\": {\"url\": url},\n",
    "                \"type\": \"image_url\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "response = openai_client.chat.completions.create(model=OPENAI_MODEL, messages=messages, temperature=0.5)\n",
    "\n",
    "display(Image(url=url, width=200))\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
