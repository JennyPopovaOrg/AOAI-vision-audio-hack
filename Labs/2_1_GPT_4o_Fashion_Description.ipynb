{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816bdc6f",
   "metadata": {},
   "source": [
    "# Azure OpenAI GPT-4o Vision in fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e815973",
   "metadata": {},
   "source": [
    "GPT-4o with Vision capabilities on Azure OpenAI service is a large multimodal model (LMM) developed by OpenAI that can analyze images and provide textual responses to questions about them. It incorporates both natural language processing and visual understanding. With enhanced mode, you can use the Azure AI Vision features to generate additional insights from the images.\n",
    "> https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?tabs=python-secure%2Cglobal-standard%2Cstandard-chat-completions#gpt-4o-and-gpt-4-turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e5b8c",
   "metadata": {},
   "source": [
    "In this lab, you will learn how the Azure OpenAI GPT-4 model can be applied to the fashion industry. \n",
    "The model will be instructed to extract fasion features from images and create content for garment promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea10d00",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a4ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f612244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_openai_version():\n",
    "    \"\"\"\n",
    "    Check Azure Open AI version\n",
    "    \"\"\"\n",
    "    installed_version = openai.__version__\n",
    "\n",
    "    try:\n",
    "        version_number = float(installed_version[:3])\n",
    "    except ValueError:\n",
    "        print(\"Invalid OpenAI version format\")\n",
    "        return\n",
    "\n",
    "    print(f\"Installed OpenAI version: {installed_version}\")\n",
    "\n",
    "    if version_number < 1.0:\n",
    "        print(\"[Warning] You should upgrade OpenAI to have version >= 1.0.0\")\n",
    "        print(\"To upgrade, run: %pip install openai --upgrade\")\n",
    "    else:\n",
    "        print(f\"[OK] OpenAI version {installed_version} is >= 1.0.0\")\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "check_openai_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742a495",
   "metadata": {},
   "source": [
    "## 1. Azure Open AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc817c20",
   "metadata": {},
   "source": [
    "load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89590d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gpt-4o\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "# Azure Open AI\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "model =   os.getenv(\"AZURE_OPENAI_MODEL\")  # This is the deployed name of your GPT4o model from the Azure Open AI studio\n",
    "print(\"Model: \",  model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336cfa",
   "metadata": {},
   "source": [
    "## 2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5767d",
   "metadata": {},
   "source": [
    "Function to display image from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to display image\n",
    "def image_view(image_file):\n",
    "    \"\"\"\n",
    "    View image\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_file):\n",
    "        print(f\"[Error] Image file {image_file} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        print(image_file)\n",
    "        img = Image.open(image_file)\n",
    "        display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e68f20",
   "metadata": {},
   "source": [
    "Function to generate image description with focus on fashion features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82d63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4V_fashion(image_file):\n",
    "    \"\"\"\n",
    "    GPT4-Vision\n",
    "    \"\"\"\n",
    "    # Checking if file exists\n",
    "    if not os.path.exists(image_file):\n",
    "        print(f\"[Error] Image file {image_file} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # Endpoint\n",
    "    base_url = f\"{openai.api_base}/openai/deployments/{model}\"\n",
    "    gpt4vision_endpoint = f\"{base_url}/chat/completions?api-version={openai.api_version}\"\n",
    "\n",
    "\n",
    "    # Header\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai.api_key}\n",
    "\n",
    "    # Encoded image\n",
    "    encoded_image = base64.b64encode(open(image_file, \"rb\").read()).decode(\n",
    "        \"ascii\"\n",
    "    )\n",
    "\n",
    "    context = \"\"\" \n",
    "    You are a fashion expert, familiar with identifying features of fashion articles from images.\n",
    "    A user uploads an image and asks you to describe one particular piece in the shot: jacket, shoes, pants, \\\n",
    "    watches, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You respond with your analysis of the following fields:\n",
    "\n",
    "    1. ITEM'S TYPE: Identify if it's a top, bottom, dress, outerwear, footwear, bag, jewelry...\n",
    "    2. BRAND: identity the brand of the item.\n",
    "    3. COLOR: Note the main color(s) and any secondary colors.\n",
    "    4. PATTERN: Identify any visible patterns such as stripes, florals, animal print, or geometric designs.\\\n",
    "    Feel free to use any other patterns here.\n",
    "    5. MATERIAL: Best guess at the material that the item is made from.\n",
    "    6. FEATURES: Note any unique details or embellishments, like embroidery, sequins, studs, fringes, buttons,\n",
    "    zippers...\n",
    "    7. ITEM TYPE SPECIFIC: For each type of item, feel free to add any additional descriptions that are relevant \\\n",
    "    to help describe the item. For example, for a jacket you can include the neck and sleeve design, plus the length.\n",
    "    8. MISC.: Anything else important that you notice.\n",
    "    9. SIZE: Print the size of the item if you get it from the image.\n",
    "    10. ITEM SUMMARY: Write a one line summary for this item.\n",
    "    11. ITEM CLASSIFICATION: Classify this item into CLOTHES, BAG, SHOES, WATCH or OTHERS.\n",
    "    12. ITEM TAGS: Generate 10 tags to describe this item. Each tags should be separated with a comma.\n",
    "    13. STORIES: Write multiple stories about this product in 5 lines.\n",
    "    14. TWEETER PUBLICATION: Write a tweeter ad for this item with some hashtags and emojis.\n",
    "    15. ECOMMERCE AD: Generate an item description for a publication on a ecommerce website with a selling message.\n",
    "    16. SWEDISH ECOMMERCE AD: Generate an item description in Swedish for a publication on a ecommerce website with \\\n",
    "    a selling message.\n",
    "\n",
    "    The output should be a numbered bulleted list. Just print an empty line between each items starting at item 12.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    json_data = {\n",
    "        \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": context\n",
    "        }\n",
    "      ]\n",
    "    }, \n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    "\n",
    "    # Results\n",
    "    response = requests.post(\n",
    "        gpt4vision_endpoint, headers=headers, data=json.dumps(json_data)\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        now = str(datetime.datetime.today().strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "        print(f\"Analysis of image: {image_file}\")\n",
    "        resp = json.loads(response.text)[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(\"\\033[1;31;34m\")\n",
    "        print(resp)\n",
    "        print(\"\\n\\033[1;31;32mDone:\", now)\n",
    "        print(\n",
    "            \"\\033[1;31;32m[Note] These results are generated by an AI (Azure Open AI GPT4-Vision)\"\n",
    "        )\n",
    "\n",
    "    elif response.status_code == 429:\n",
    "        print(\n",
    "            \"[429 Error] Too many requests. Please wait a couple of seconds and try again.\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"[Error] Error code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c71e0",
   "metadata": {},
   "source": [
    "## 3. Examples\n",
    "\n",
    "Let's try to analyse an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image1.jpg\"\n",
    "\n",
    "image_view(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab74421",
   "metadata": {},
   "source": [
    "Run GPT-4o analysis. Notice that the model can provide very reach content in just one-go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GPT4-Vision\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e9ebb",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image2.jpg\"\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7742a",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image3.png\"\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f9961",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3373d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image4.jpg\"\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa9b7f",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49657e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image5.jpg\"\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431735d0",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68947083",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image6.png\"\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fd1e5",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04573407",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image7.jpg\"\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ac884",
   "metadata": {},
   "source": [
    "### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/fashion/image8.jpg\"\n",
    "\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db66011",
   "metadata": {},
   "source": [
    "## 4. Challenge\n",
    "1. Create description for your own fashion image(s)\n",
    "2. Modify prompt in gpt4V_fashion function to create different content for an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"...\" # Add your image file here\n",
    "\n",
    "image_view(image_file)\n",
    "gpt4V_fashion(image_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
