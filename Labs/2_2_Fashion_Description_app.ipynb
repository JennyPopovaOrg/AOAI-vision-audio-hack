{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816bdc6f",
   "metadata": {},
   "source": [
    "# Build a fashion app for image description\n",
    "\n",
    "An optional lab to see how a simple fashio app can be built with GPT-4o model and Gradio framework\n",
    "\n",
    "https://www.gradio.app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37903e3f",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import gradio as gr\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742a495",
   "metadata": {},
   "source": [
    "Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89590d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)  \n",
    "\n",
    "# Azure Open AI\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "model =   os.getenv(\"AZURE_OPENAI_MODEL\")  # This is the deployed name of your GPT4o model from the Azure Open AI studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da57df",
   "metadata": {},
   "source": [
    "## Gradio WebApp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef445f",
   "metadata": {},
   "source": [
    "**Function to generate image description with focus on fashion features**\n",
    "\n",
    "The function is designed to interact with the **GPT-4 Vision** model to analyze and describe fashion items from an uploaded image. The function takes an image file as input and processes it to generate a detailed description of the fashion item in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4V_fashion_webapp(pil_image):\n",
    "    \"\"\"\n",
    "    GPT4-Vision\n",
    "    \"\"\"\n",
    "    # Endpoint\n",
    "    base_url = f\"{openai.api_base}/openai/deployments/{model}\"\n",
    "    gpt4vision_endpoint = f\"{base_url}/chat/completions?api-version={openai.api_version}\"\n",
    "\n",
    "    # Header\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": openai.api_key}\n",
    "\n",
    "    # Encoded PIL image\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    encoded_image = base64.b64encode(buffered.getvalue()).decode(\"ascii\")\n",
    "\n",
    "    context = \"\"\" \n",
    "    You are a fashion expert, familiar with identifying features of fashion articles from images.\n",
    "    A user will upload an image and asks you to describe one particular piece in the shot: jacket, shoes, pants, \\\n",
    "    watches, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You respond with your analysis of the following fields:\n",
    "\n",
    "    1. ITEM'S TYPE: Identify if it's a top, bottom, dress, outerwear, footwear, bag, jewelry...\n",
    "    2. BRAND: identity the brand of the item.\n",
    "    3. COLOR: Note the main color(s) and any secondary colors.\n",
    "    4. PATTERN: Identify any visible patterns such as stripes, florals, animal print, or geometric designs.\\\n",
    "    Feel free to use any other patterns here.\n",
    "    5. MATERIAL: Best guess at the material that the item is made from.\n",
    "    6. FEATURES: Note any unique details or embellishments, like embroidery, sequins, studs, fringes, buttons,\n",
    "    zippers...\n",
    "    7. ITEM TYPE SPECIFIC: For each type of item, feel free to add any additional descriptions that are relevant \\\n",
    "    to help describe the item. For example, for a jacket you can include the neck and sleeve design, plus the length.\n",
    "    8. MISC.: Anything else important that you notice.\n",
    "    9. SIZE: Print the size of the item if you get it from the image.\n",
    "    10. ITEM SUMMARY: Write a one line summary for this item.\n",
    "    11. ITEM CLASSIFICATION: Classify this item into CLOTHES, BAG, SHOES, WATCH or OTHERS.\n",
    "    12. ITEM TAGS: Generate 10 tags to describe this item. Each tags should be separated with a comma.\n",
    "    13. STORIES: Write multiple stories about this product in 5 lines.\n",
    "    14. TWEETER PUBLICATION: Write a tweeter ad for this item with some hashtags and emojis.\n",
    "    15. ECOMMERCE AD: Generate an item description for a publication on a ecommerce website with a selling message.\n",
    "    16. FRENCH ECOMMERCE AD: Generate an item description in French for a publication on a ecommerce website with \\\n",
    "    a selling message.\n",
    "\n",
    "    The output should be a numbered bulleted list. Just print an empty line between each items starting at item 12.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    json_data = {\n",
    "        \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": context\n",
    "        }\n",
    "      ]\n",
    "    }, \n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "        \"max_tokens\": 4000,\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    "\n",
    "    # Results\n",
    "    response = requests.post(\n",
    "        gpt4vision_endpoint, headers=headers, data=json.dumps(json_data)\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        resp = json.loads(response.text)[\"choices\"][0][\"message\"][\"content\"]\n",
    "        resp1, resp2 = resp.split(\"13. STORIES:\", 1)\n",
    "        resp1 = resp1.replace(\"\\n\\n\", \"  \")\n",
    "        resp2 = \"13. STORIES:\" + resp2\n",
    "        return resp1, resp2\n",
    "\n",
    "    elif response.status_code == 429:\n",
    "        msg1 = \"[429 Error] Too many requests. Please wait a couple of seconds and try again.\"\n",
    "        msg2 = msg1\n",
    "        return msg1, msg2\n",
    "\n",
    "    else:\n",
    "        msg1 = str(response.status_code)\n",
    "        msg2 = msg1\n",
    "        return msg1, msg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d88b5",
   "metadata": {},
   "source": [
    "**Define an app**\n",
    "\n",
    "Here we are defining an application inputs, outputs and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = (\n",
    "    \"https://raw.githubusercontent.com/retkowsky/images/master/fashion-logo-design.jpg\"\n",
    ")\n",
    "logo = \"<center> <img src= {} width=200px></center>\".format(image_url)\n",
    "title = \"GPT-4 Vision demo with Azure Open AI - Fashion usecase\"\n",
    "\n",
    "examples = [\n",
    "    \"../data/fashion/image1.jpg\",\n",
    "    \"../data/fashion/image2.jpg\",\n",
    "    \"../data/fashion/image3.png\",\n",
    "    \"../data/fashion/image4.jpg\",\n",
    "    \"../data/fashion/image5.jpg\",\n",
    "    \"../data/fashion/image6.png\",\n",
    "    \"../data/fashion/image7.jpg\",\n",
    "    \"../data/fashion/image8.jpg\",\n",
    "]\n",
    "\n",
    "inputs = gr.Image(type=\"pil\", label=\"Your image\")\n",
    "outputs = [\n",
    "    gr.Text(label=\"Product image insights\"),\n",
    "    gr.Text(label=\"Marketing content\"),\n",
    "]\n",
    "\n",
    "theme = \"rottenlittlecreature/Moon_Goblin\"\n",
    "# https://huggingface.co/spaces/gradio/theme-gallery\n",
    "\n",
    "gpt4V_fashion_gradiowebapp = gr.Interface(\n",
    "    fn=gpt4V_fashion_webapp,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    description=logo,\n",
    "    title=title,\n",
    "    examples=examples,\n",
    "    theme=theme,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bf2f8",
   "metadata": {},
   "source": [
    "**Run the app**\n",
    "\n",
    "Note that you can upload your own images or use inputs from camera or clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4V_fashion_gradiowebapp.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
